# Temporal Empathy Vision System

A **real-time AI system** that detects emotions, body poses, and voice sentiment using your **built-in webcam and microphone**. Designed to run smoothly on **Mac M1/M2**, **Windows**, and Linux systems.

---

## ğŸ”¹ Features

- **Facial Emotion Detection**: Detect micro-expressions in real-time using DeepFace.
- **Body Pose Analysis**: Track gestures and body posture with MediaPipe.
- **Voice Sentiment Analysis**: Capture audio and detect excitement or calmness.
- **Emotional Dashboard**: Visualize the overall emotional state with a live dashboard.
- **Cross-Platform**: Works on Mac (with `tensorflow-metal` for GPU), Windows, and Linux.

---

## ğŸ› ï¸ Folder Structure
temporal_empathy/
â”‚
â”œâ”€ temporal_empathy/      # Python source files
â”‚   â”œâ”€ main.py
â”‚   â”œâ”€ emotion_detector.py
â”‚   â”œâ”€ pose_detector.py
â”‚   â”œâ”€ voice_analyzer.py
â”‚   â””â”€ dashboard.py
â”œâ”€ requirements.txt       # Dependencies
â”œâ”€ README.md
â””â”€ venv/                  # Virtual environment (ignored in Git


---

## âš¡ Requirements

Install Python 3.11 or later.  

**Dependencies (cross-platform):**
opencv-python
mediapipe
deepface
numpy
pyttsx3
sounddevice
librosa
matplotlib
scipy
torch
tensorflow


> For Mac M1/M2, replace `tensorflow` with:
>
> tensorflow-macos
tensorflow-metal
>
> ---

## ğŸš€ Installation

1. Clone the repository:

```bash
git clone https://github.com/rohitmannur007/temporal_empathy.git
cd temporal_empathy

	2.	Create and activate a virtual environment:
python3.11 -m venv venv
source venv/bin/activate   # Mac/Linux
# .\venv\Scripts\activate  # Windows


	3.	Upgrade pip and install dependencies:
pip install --upgrade pip
pip install -r requirements.txt

ğŸ¬ How to Run
source venv/bin/activate   # Mac/Linux
# .\venv\Scripts\activate  # Windows

python temporal_empathy/main.py

	â€¢	The webcam opens and detects facial emotions and body poses.
	â€¢	Microphone analyzes voice sentiment every 3 seconds.
	â€¢	Emotional dashboard shows a real-time map of all detected emotions.
	â€¢	Press ESC to exit.

â¸»

ğŸ’¡ Future Enhancements
	â€¢	Multi-person tracking
	â€¢	Gesture-based AI suggestions
	â€¢	Integration with AR/VR for immersive emotional interaction
	â€¢	Logging and analytics for emotion trends over time

â¸»

ğŸ“ License

MIT License Â© 2025 Rohit Mannur

â¸»

ğŸ”— Contact
	â€¢	GitHub: rohitmannur007

	â€¢	The webcam opens and detects facial emotions and body poses.
	â€¢	Microphone analyzes voice sentiment every 3 seconds.
	â€¢	Emotional dashboard shows a real-time map of all detected emotions.
	â€¢	Press ESC to exit.

â¸»

ğŸ’¡ Future Enhancements
	â€¢	Multi-person tracking
	â€¢	Gesture-based AI suggestions
	â€¢	Integration with AR/VR for immersive emotional interaction
	â€¢	Logging and analytics for emotion trends over time

â¸»

ğŸ“ License

MIT License Â© 2025 Rohit Mannur

â¸»

ğŸ”— Contact
	â€¢	GitHub: rohitmannur007

	â€¢	The webcam opens and detects facial emotions and body poses.
	â€¢	Microphone analyzes voice sentiment every 3 seconds.
	â€¢	Emotional dashboard shows a real-time map of all detected emotions.
	â€¢	Press ESC to exit.

â¸»

ğŸ’¡ Future Enhancements
	â€¢	Multi-person tracking
	â€¢	Gesture-based AI suggestions
	â€¢	Integration with AR/VR for immersive emotional interaction
	â€¢	Logging and analytics for emotion trends over time

â¸»

ğŸ“ License

MIT License Â© 2025 Rohit Mannur

â¸»

ğŸ”— Contact
	â€¢	GitHub: rohitmannur007
---

